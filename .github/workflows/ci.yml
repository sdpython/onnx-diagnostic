name: ci

on:
  push:
  pull_request:
    types:
      - closed
    branches:
      - main

jobs:
  run:
    name: to-${{ matrix.torch }}-tr-${{ matrix.transformers }}-ci ${{ matrix.os }}-${{ matrix.python }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]
        python: ['3.11', '3.12']
        transformers: ['4.48.3', '4.51.1', 'main']
        torch: ['2.6', 'main']

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}

      - name: Install pytorch
        run: |
          if [[ "${{ matrix.torch }}" == "main" ]]; then
            python -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
          else
            echo "install torch==${{ matrix.torch }}"
            pip install torch==${{ matrix.torch }}
          fi

      - name: Install transformers ${{ matrix.transformers }}
        run: |
          if [[ "${{ matrix.transformers }}" == "main" ]]; then
            echo "install transformers from github"
            git clone https://github.com/huggingface/transformers.git
            cd transformers
            pip install -e .
            cd ..
          else
            echo "install transformers==${{ matrix.transformers }}"
            pip install transformers==${{ matrix.transformers }}
          fi

      - name: Install requirements
        run: python -m pip install -r requirements.txt

      - name: Install requirements dev
        run: python -m pip install -r requirements-dev.txt

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            ${{ runner.os }}-

      - name: pip freeze
        run: python -m pip freeze

      - name: tiny-llm torch.export.export
        run: |
          export PYTHONPATH=.
          python _unittests/ut_torch_models/test_tiny_llms.py

      - name: tiny-llm onnx
        run: |
          export PYTHONPATH=.
          python _unittests/ut_torch_models/test_tiny_llms_onnx.py
        continue-on-error: true  # connectivity issues

      - name: tiny-llm example
        run: |
          export PYTHONPATH=.
          python _doc/examples/plot_export_tiny_llm.py
        continue-on-error: true  # connectivity issues

      - name: tiny-llm bypass
        run: |
          export PYTHONPATH=.
          python _doc/examples/plot_export_tiny_llm_patched.py
        continue-on-error: true  # connectivity issues

      - name: run tests
        run: |
          pip install pytest
          export PYTHONPATH=.
          UNITTEST_GOING=1 pytest --durations=10 _unittests --ignore _unittests/ut_reference/test_backend_extended_reference_evaluator.py --ignore _unittests/ut_reference/test_backend_onnxruntime_evaluator.py
          export PYTHONPATH=

      - name: run backend tests python
        run: |
          pip install pytest
          export PYTHONPATH=.
          UNITTEST_GOING=1 pytest --durations=10 _unittests/ut_reference/test_backend_extended_reference_evaluator.py
          export PYTHONPATH=

      - name: run backend tests onnxruntime
        run: |
          pip install pytest
          export PYTHONPATH=.
          UNITTEST_GOING=1 pytest --durations=10 _unittests/ut_reference/test_backend_onnxruntime_evaluator.py --maxfail=15
          export PYTHONPATH=
