name: MODELS

on:
  push:
  pull_request:
    types:
      - closed
    branches:
      - main

jobs:
  run:
    name: to-${{ matrix.torch }}-tr-${{ matrix.transformers }}-ci ${{ matrix.os }}-${{ matrix.python }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python: ['3.13']
        transformers: ['5.0']
        torch: ['main']
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}

      - name: Install pytorch ${{ matrix.torch }}
        run: |
          if [[ "${{ matrix.torch }}" == "main" ]]; then
            python -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
          else
            echo "install torch==${{ matrix.torch }} torchvision torchaudio"
            pip install torch==${{ matrix.torch }} torchvision torchaudio
          fi

      - name: Install transformers ${{ matrix.transformers }}
        run: |
          if [[ "${{ matrix.transformers }}" == "main" ]]; then
            echo "install transformers from github"
            git clone https://github.com/huggingface/transformers.git
            cd transformers
            pip install -e .
            cd ..
          else
            echo "install transformers==${{ matrix.transformers }}"
            pip install transformers==${{ matrix.transformers }}
          fi

      - name: Install requirements
        run: python -m pip install -r requirements.txt

      - name: Install requirements dev
        run: python -m pip install -r requirements-dev.txt

      - name: Uninstall onnx-diagnostic
        run: python -m pip uninstall -y onnx-diagnostic

      - name: pip freeze
        run: python -m pip freeze

      - name: qwen2.5_vl_instruct - visual
        run: |
          PYTHONPATH=. python -m onnx_diagnostic.ci_models.export_qwen25_vl -m Qwen/Qwen2.5-VL-7B-Instruct --device cpu --dtype float16 --exporter custom --no-pretrained --no-second-input --atol 0.05

      - name: qwen2.5_vl_instruct - embedding
        run: |
          PYTHONPATH=. python -m onnx_diagnostic.ci_models.export_qwen25_vl -m Qwen/Qwen2.5-VL-7B-Instruct --device cpu --dtype float32 --exporter custom --no-pretrained --no-second-input --atol 0.05 --part embedding
          rm dump_models -rf
